{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c74ba36-20ca-4675-96de-4934cc0c5d7e",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f687937-53dd-4b11-ad81-74735e9c3246",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T08:38:57.260473Z",
     "iopub.status.busy": "2025-03-10T08:38:57.259698Z",
     "iopub.status.idle": "2025-03-10T08:38:59.576096Z",
     "shell.execute_reply": "2025-03-10T08:38:59.575749Z",
     "shell.execute_reply.started": "2025-03-10T08:38:57.260436Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, torch\n",
    "from random import randint\n",
    "from numpy import repeat\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "from pi import pi_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7353c2d8-3e80-43e9-b136-e496a18d859f",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6cff426-4831-427e-8a90-22edfdee3ee0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T08:38:59.576994Z",
     "iopub.status.busy": "2025-03-10T08:38:59.576844Z",
     "iopub.status.idle": "2025-03-10T08:39:06.103354Z",
     "shell.execute_reply": "2025-03-10T08:39:06.102879Z",
     "shell.execute_reply.started": "2025-03-10T08:38:59.576985Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_model = 'openai-community/gpt2-xl'\n",
    "# pretrained_model = 'EleutherAI/gpt-neo-1.3B' ## Takes very long....\n",
    "# pretrained_model = 'perplexity-ai/r1-1776' ## Bloody large...\n",
    "# pretrained_model = 'meta-llama/Llama-3.2-3B-Instruct' ## Doesn't seem to work well\n",
    "\n",
    "pretrained_model_name = pretrained_model.split(\"/\")[-1]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model     = AutoModelForCausalLM.from_pretrained(pretrained_model).to('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eec7e40-8049-442c-8cdc-4d0817dadbe1",
   "metadata": {},
   "source": [
    "# Debug Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f22fffba-42e0-44fc-acbb-c756b483b77a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T08:39:54.302605Z",
     "iopub.status.busy": "2025-03-10T08:39:54.301805Z",
     "iopub.status.idle": "2025-03-10T08:39:54.310896Z",
     "shell.execute_reply": "2025-03-10T08:39:54.309585Z",
     "shell.execute_reply.started": "2025-03-10T08:39:54.302566Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"The poet do not simply\\n 'predict' the next word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f00b969-8909-4d9f-a5cf-2499b978d403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T08:39:54.874908Z",
     "iopub.status.busy": "2025-03-10T08:39:54.870969Z",
     "iopub.status.idle": "2025-03-10T08:40:04.704059Z",
     "shell.execute_reply": "2025-03-10T08:40:04.703793Z",
     "shell.execute_reply.started": "2025-03-10T08:39:54.874840Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The poet do not simply\n",
      "The poet do not simplyrd;\n",
      "The poet do not simplyrd; she\n",
      "The poet do not simplyrd; she has\n",
      "The poet do not simplyrd; she has '\n",
      "The poet do not simplyrd; she has 'made\n",
      "The poet do not simplyrd; she has 'made her\n",
      "The poet do not simplyrd; she has 'made her words\n",
      "The poet do not simplyrd; she has 'made her words fit\n",
      "The poet do not simplyrd; she has 'made her words fit her\n",
      "The poet do not simplyrd; she has 'made her words fit her context\n",
      "The poet do not simplyrd; she has 'made her words fit her context';\n",
      "The poet do not simplyrd; she has 'made her words fit her context'; in\n",
      "The poet do not simplyrd; she has 'made her words fit her context'; in a\n",
      "The poet do not simplyrd; she has 'made her words fit her context'; in a sentence\n",
      "The poet do not simplyrd; she has 'made her words fit her context'; in a sentence of\n",
      "The poet do not simplyrd; she has 'made her words fit her context'; in a sentence of two\n",
      "The poet do not simplyrd; she has 'made her words fit her context'; in a sentence of two sentences\n",
      "The poet do not simplyrd; she has 'made her words fit her context'; in a sentence of two sentences (\n",
      "The poet do not simplyrd; she has 'made her words fit her context'; in a sentence of two sentences (and\n",
      "The poet do not simplyrd; she has 'made her words fit her context'; in a sentence of two sentences (and not\n",
      "The poet do not simplyrd; she has 'made her words fit her context'; in a sentence of two sentences (and not of\n",
      "The poet do not simplyrd; she has 'made her words fit her context'; in a sentence of two sentences (and not of five\n",
      "The poet do not simplyrd; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content.\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has '\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all').\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She '\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 's\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us,\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both direct\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [direct\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words];\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [direct\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by '\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking the\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking the thing\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking the thing one\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking the thing one is\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking the thing one is speaking\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking the thing one is speaking,\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking the thing one is speaking, rather\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking the thing one is speaking, rather then\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking the thing one is speaking, rather then making\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking the thing one is speaking, rather then making up\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking the thing one is speaking, rather then making up its\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking the thing one is speaking, rather then making up its form\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking the thing one is speaking, rather then making up its form,\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking the thing one is speaking, rather then making up its form, style\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "The poet do not simply or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking the thing one is speaking, rather then making up its form, style etc\n",
      " 'predict' the next word; she has 'made her words fit her context'; in a sentence of two sentences (and not of five);\n",
      "In poetry of any style or content. (A good sentence has 'one and all'). She 'saves us, by means both directness [directiveness or simplicity in form of words]; [directive style is one's way or means by 'speaking the thing one is speaking, rather then making up its form, style etc."
     ]
    }
   ],
   "source": [
    "stopwords = [0, 13, 30, 3548, 3228, 50256] \n",
    "# exclamation mark, fullstop, question mark, two question marks, \n",
    "# two exclamation marks, EOS.\n",
    "\n",
    "write_out = []\n",
    "scores = []\n",
    "\n",
    "N = 5\n",
    "generated = prompt\n",
    "\n",
    "token_count = 1\n",
    "# token_id = 0\n",
    "keep_generating = True\n",
    "\n",
    "while keep_generating:\n",
    "    sys.stdout.flush()\n",
    "    encoded = tokenizer(generated, return_tensors=\"pt\").to(\"mps\")\n",
    "    \n",
    "    # Get output from decoder.\n",
    "    outputs = model.generate(**encoded,\n",
    "                             return_dict_in_generate=True, \n",
    "                             output_scores=True,\n",
    "                             # output_hidden_states=True,\n",
    "                             max_new_tokens=1,\n",
    "                             do_sample=False,\n",
    "                             pad_token_id=50256 #128001\n",
    "                             )\n",
    "    \n",
    "    # Convert to probabilities.\n",
    "    probs = torch.nn.functional.softmax(outputs.scores[0], dim=1).cpu()\n",
    "    \n",
    "    # Roll my own lookup.\n",
    "    probs = pd.DataFrame(probs.tolist()[0])\n",
    "    probs.columns = ['probability']\n",
    "    probs.sort_values(ascending=False, by='probability', inplace=True)\n",
    "    \n",
    "    ## We can:\n",
    "    ## 1. Always take the nth most likely token.\n",
    "    topN = probs.head(N+1).copy()\n",
    "    topN.loc[:, \"token_count\"] = repeat(token_count, len(topN))\n",
    "    scores.append(topN)\n",
    "\n",
    "    token_id = probs.index[N]\n",
    "\n",
    "    if token_count > 77:\n",
    "        if any(item in topN.index for item in stopwords):\n",
    "            # take the least likely ending token\n",
    "            token_id = [idx for idx in topN.index if idx in stopwords][-1]\n",
    "            keep_generating = False\n",
    "    #     else:\n",
    "    #         token_id = probs.index[N]\n",
    "    # else:\n",
    "    #     token_id = probs.index[N]\n",
    "\n",
    "    ## 2. Pick a random token from the top 10.\n",
    "    # token_id = probs.index[randint(4, 9)] # 5th to 9th place.\n",
    "\n",
    "    ## 3. Use the digits of pi!\n",
    "    # token_id = probs.index[int(d)]\n",
    "\n",
    "    generated = generated + tokenizer.decode(token_id, \n",
    "                                             skip_special_tokens=True, \n",
    "                                             clean_up_tokenization_spaces=True)\n",
    "\n",
    "\n",
    "    # Update token count.\n",
    "    token_count += 1\n",
    "\n",
    "    sys.stdout.write(f\"\\r{generated}\")\n",
    "\n",
    "scores = pd.concat(scores)\n",
    "scores.loc[:, \"decoded\"] = scores.index.map(lambda x: tokenizer.decode(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c601e0e-e23a-4692-8b83-7bf2ed952086",
   "metadata": {},
   "source": [
    "# Main functional loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc88e313-2b2d-4844-9e71-289f3b81f8ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T03:29:30.963753Z",
     "iopub.status.busy": "2025-03-10T03:29:30.961641Z",
     "iopub.status.idle": "2025-03-10T03:29:30.977986Z",
     "shell.execute_reply": "2025-03-10T03:29:30.976547Z",
     "shell.execute_reply.started": "2025-03-10T03:29:30.963564Z"
    }
   },
   "outputs": [],
   "source": [
    "# prompts = [\"Humans do not simply predict the next word.\",\n",
    "#            \"Longing for an unlikely outcome,\",\n",
    "#            \"Do you enjoy listening to a detuned piano?\",\n",
    "#            \"The mirrors always break in the same ways.\",\n",
    "#            \"This tongue is inevitably forked.\"\n",
    "#           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afaa8787-fcc2-4659-b0d6-52c133c101a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T03:29:45.100462Z",
     "iopub.status.busy": "2025-03-10T03:29:45.099482Z",
     "iopub.status.idle": "2025-03-10T03:35:58.460630Z",
     "shell.execute_reply": "2025-03-10T03:35:58.459398Z",
     "shell.execute_reply.started": "2025-03-10T03:29:45.100413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Humans do not simply predict the next word.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for prompt in prompts:\n",
    "    \n",
    "#     print(prompt)\n",
    "    \n",
    "#     write_out = []\n",
    "#     # scores = []\n",
    "#     to_write = []\n",
    "    \n",
    "#     # for idx, d in enumerate(pi_digits[:100]):\n",
    "#     for N in [4,5,6,7,8,9]:\n",
    "\n",
    "#         generated = prompt\n",
    "\n",
    "#         token_count = 1\n",
    "#         # token_id = 0\n",
    "#         keep_generating = True\n",
    "        \n",
    "#         while keep_generating:\n",
    "#             encoded = tokenizer(generated, return_tensors=\"pt\").to(\"mps\")\n",
    "            \n",
    "#             # Get output from decoder.\n",
    "#             outputs = model.generate(**encoded,\n",
    "#                                      return_dict_in_generate=True, \n",
    "#                                      output_scores=True,\n",
    "#                                      # output_hidden_states=True,\n",
    "#                                      max_new_tokens=1,\n",
    "#                                      do_sample=False,\n",
    "#                                      pad_token_id=50256 #128001\n",
    "#                                      )\n",
    "            \n",
    "#             # Convert to probabilities.\n",
    "#             probs = torch.nn.functional.softmax(outputs.scores[0], dim=1).cpu()\n",
    "            \n",
    "#             # Roll my own lookup.\n",
    "#             probs = pd.DataFrame(probs.tolist()[0])\n",
    "#             probs.columns = ['probability']\n",
    "#             probs.sort_values(ascending=False, by='probability', inplace=True)\n",
    "            \n",
    "#             ## We can:\n",
    "#             ## 1. Always take the nth most likely token.\n",
    "#             topN = probs.head(N+1).copy()\n",
    "#             # topN.loc[:, \"token_count\"] = repeat(token_count, len(topN))\n",
    "#             # scores.append(topN)\n",
    "        \n",
    "#             if token_count > 77:\n",
    "#                 if any(item in topN.index for item in [0, 13, 30, 3548, 3228, 50256]):\n",
    "#                     # exclamation mark, fullstop, question mark, two question marks, \n",
    "#                     # two exclamation marks, EOS.\n",
    "#                     token_id = 13\n",
    "#                     keep_generating = False\n",
    "#             else:\n",
    "#                 token_id = probs.index[N]\n",
    "        \n",
    "#             ## 2. Pick a random token from the top 10.\n",
    "#             # token_id = probs.index[randint(4, 9)] # 5th to 9th place.\n",
    "        \n",
    "#             ## 3. Use the digits of pi!\n",
    "#             # token_id = probs.index[int(d)]\n",
    "        \n",
    "#             generated = generated + tokenizer.decode(token_id, \n",
    "#                                                      skip_special_tokens=True, \n",
    "#                                                      clean_up_tokenization_spaces=True)\n",
    "        \n",
    "        \n",
    "#             # Update token count.\n",
    "#             token_count += 1\n",
    "        \n",
    "#         # scores = pd.concat(scores)\n",
    "#         write_out.append(f\"N = {N+1}\\n\" + generated + \"\\n\\n\")\n",
    "\n",
    "#     # Writing multiple lines to the file\n",
    "#     with open(f'generations/{pretrained_model_name}-{prompt}.txt', 'w') as out:\n",
    "#         out.writelines(write_out)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b73598-0a3c-47e9-af7d-57106c6c9805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4cdb312-9d1a-47a4-93ba-a2a01190b606",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Recycle Bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c69b2f53-819d-42cf-918e-36cfbdab60da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T09:02:43.059419Z",
     "iopub.status.busy": "2025-03-06T09:02:43.058789Z",
     "iopub.status.idle": "2025-03-06T09:02:43.064232Z",
     "shell.execute_reply": "2025-03-06T09:02:43.063368Z",
     "shell.execute_reply.started": "2025-03-06T09:02:43.059394Z"
    }
   },
   "outputs": [],
   "source": [
    "# N = 25\n",
    "# topN = torch.topk(probs, N, sorted=True)\n",
    "# bottomN = torch.topk(probs, N, largest=False, sorted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "07eb4466-4745-4d4e-92ab-1c938d22aa99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T09:02:43.066228Z",
     "iopub.status.busy": "2025-03-06T09:02:43.065890Z",
     "iopub.status.idle": "2025-03-06T09:02:43.072414Z",
     "shell.execute_reply": "2025-03-06T09:02:43.071181Z",
     "shell.execute_reply.started": "2025-03-06T09:02:43.066195Z"
    }
   },
   "outputs": [],
   "source": [
    "# high = 6\n",
    "# low  = 9\n",
    "\n",
    "# [prompt + newToken \n",
    "#      for newToken in \n",
    "#      gpt2_tokenizer.batch_decode(probs.index[high].tolist(), \n",
    "#                                  skip_special_tokens=True,\n",
    "#                                  clean_up_tokenization_spaces=True)\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac448482-096b-4488-8baf-9346cd4a680b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codepoet Py3.10",
   "language": "python",
   "name": "codepoet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
